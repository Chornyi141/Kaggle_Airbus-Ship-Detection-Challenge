{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09ac11b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-02T18:20:01.196224Z",
     "iopub.status.busy": "2023-06-02T18:20:01.195870Z",
     "iopub.status.idle": "2023-06-02T18:20:11.440784Z",
     "shell.execute_reply": "2023-06-02T18:20:11.439803Z",
     "shell.execute_reply.started": "2023-06-02T18:20:01.196196Z"
    }
   },
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "\n",
    "# tensorflow\n",
    "import tensorflow as tf\n",
    "\n",
    "# keras\n",
    "from keras.layers import Input, Conv2D, Conv2DTranspose, MaxPooling2D, Dropout, concatenate, BatchNormalization\n",
    "from keras.models import Model\n",
    "\n",
    "# other\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import albumentations as A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c39ba23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "\n",
    "# set pathes \n",
    "test_folder = './test_v2/'\n",
    "train_folder = './train_v2/'\n",
    "\n",
    "# model hyperparameters\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d1ce84",
   "metadata": {},
   "source": [
    "## Load CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e88f45e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-02T18:20:17.866553Z",
     "iopub.status.busy": "2023-06-02T18:20:17.866143Z",
     "iopub.status.idle": "2023-06-02T18:20:27.549378Z",
     "shell.execute_reply": "2023-06-02T18:20:27.548060Z",
     "shell.execute_reply.started": "2023-06-02T18:20:17.866520Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EncodedPixels</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ImageId</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>00003e153.jpg</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0001124c7.jpg</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000155de5.jpg</th>\n",
       "      <td>264661 17 265429 33 266197 33 266965 33 267733...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000194a2d.jpg</th>\n",
       "      <td>360486 1 361252 4 362019 5 362785 8 363552 10 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0001b1832.jpg</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fffedbb6b.jpg</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffff2aa57.jpg</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffff6e525.jpg</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffffc50b4.jpg</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffffe97f3.jpg</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192555 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   EncodedPixels\n",
       "ImageId                                                         \n",
       "00003e153.jpg                                               None\n",
       "0001124c7.jpg                                               None\n",
       "000155de5.jpg  264661 17 265429 33 266197 33 266965 33 267733...\n",
       "000194a2d.jpg  360486 1 361252 4 362019 5 362785 8 363552 10 ...\n",
       "0001b1832.jpg                                               None\n",
       "...                                                          ...\n",
       "fffedbb6b.jpg                                               None\n",
       "ffff2aa57.jpg                                               None\n",
       "ffff6e525.jpg                                               None\n",
       "ffffc50b4.jpg                                               None\n",
       "ffffe97f3.jpg                                               None\n",
       "\n",
       "[192555 rows x 1 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read and reformat csv\n",
    "df = pd.read_csv(f'train_ship_segmentations_v2.csv')\n",
    "df = pd.DataFrame(df.groupby('ImageId')['EncodedPixels']\n",
    "                          .apply(lambda x: None if type(x.values[0]) == float else ' '.join(x.astype(str))))\n",
    "df = df.drop('6384c3e78.jpg')  # remove corrupted image\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a878cda",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-02T16:44:08.767290Z",
     "iopub.status.busy": "2023-06-02T16:44:08.766871Z",
     "iopub.status.idle": "2023-06-02T16:44:08.774449Z",
     "shell.execute_reply": "2023-06-02T16:44:08.773443Z",
     "shell.execute_reply.started": "2023-06-02T16:44:08.767258Z"
    }
   },
   "outputs": [],
   "source": [
    "# limit df\n",
    "df = df[:10000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d60397f",
   "metadata": {},
   "source": [
    "## RLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9e81289",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-02T18:20:27.552606Z",
     "iopub.status.busy": "2023-06-02T18:20:27.551862Z",
     "iopub.status.idle": "2023-06-02T18:20:27.564959Z",
     "shell.execute_reply": "2023-06-02T18:20:27.562043Z",
     "shell.execute_reply.started": "2023-06-02T18:20:27.552559Z"
    }
   },
   "outputs": [],
   "source": [
    "# creates a photo from RLE\n",
    "def RLE_decoder(RLE:str, size=(768, 768)):  \n",
    "    segmented_photo = np.zeros((size[0] * size[1]))  # 1D array for black image\n",
    "    if RLE == None:\n",
    "        return tf.image.transpose(np.reshape(segmented_photo, (size[0], size[1], 1)))\n",
    "    RLE = [int(x) for x in RLE.split(' ')]  # get RLE indices\n",
    "    for idx in range(0, len(RLE), 2):  # change segmented pixels\n",
    "        segmented_photo[ RLE[idx] : RLE[idx]+RLE[idx+1] ] = 1\n",
    "    segmented_photo = np.transpose(np.reshape(segmented_photo, (size[0], size[1], 1)), (1,0,2))  \n",
    "    return segmented_photo\n",
    "\n",
    "# creates a RLE from photo\n",
    "def RLE_encoder(segmented_photo): \n",
    "    # transpose and flatten\n",
    "    segmented_photo = np.transpose(segmented_photo, (1,0,2))\n",
    "    segmented_photo = segmented_photo.flatten() > 0.5  # segmented pixels count if its value > 0.5\n",
    "    \n",
    "    # calculate RLE\n",
    "    RLE_count = [0]\n",
    "    RLE_index = [0]\n",
    "    last_pixel = False\n",
    "    for idx in range(len(segmented_photo)):\n",
    "        pixel = segmented_photo[idx]\n",
    "        if pixel == last_pixel:  \n",
    "            RLE_count[-1] += 1\n",
    "        else:\n",
    "            RLE_count.append(1)\n",
    "            RLE_index.append(idx)\n",
    "            last_pixel = not last_pixel\n",
    "\n",
    "    # convert RLE to string\n",
    "    RLE = ''\n",
    "    for idx in range(1,len(RLE_count), 2):\n",
    "        if RLE != '':\n",
    "            RLE += ' '\n",
    "        RLE += f'{RLE_index[idx]} {RLE_count[idx]}'\n",
    "    return RLE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1b0f9e",
   "metadata": {},
   "source": [
    "## Data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "974f431b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-02T18:20:27.567308Z",
     "iopub.status.busy": "2023-06-02T18:20:27.566614Z",
     "iopub.status.idle": "2023-06-02T18:20:31.483065Z",
     "shell.execute_reply": "2023-06-02T18:20:31.481897Z",
     "shell.execute_reply.started": "2023-06-02T18:20:27.567274Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: 173300 samples\n",
      "Validation set: 19256 samples\n"
     ]
    }
   ],
   "source": [
    "# split dataframe into train and valid\n",
    "df_valid = df.sample(frac=0.1)\n",
    "df_train = df.drop(df_valid.index)\n",
    "print(f'Train set: {len(df_train)} samples')\n",
    "print(f'Validation set: {len(df_valid)} samples')\n",
    "\n",
    "# augmentations for both image and mask\n",
    "augment_both = A.Compose([\n",
    "    A.ShiftScaleRotate(shift_limit=0.3, scale_limit=0.3, rotate_limit=180, p=1, border_mode=0) \n",
    "])\n",
    "# augmentations only for image\n",
    "augment_image = A.Compose([\n",
    "    A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=1),\n",
    "    A.MultiplicativeNoise(multiplier=(0.8, 1.2))\n",
    "])\n",
    "\n",
    "# generate pair of X and Y with shuffling\n",
    "def train_generator():\n",
    "    shuffled_df = df_train.sample(frac=1)  # create shuffled df\n",
    "    while True:\n",
    "        for index, row in shuffled_df.iterrows():\n",
    "            # load image and mask\n",
    "            X = np.array(tf.keras.utils.load_img(train_folder+index))  # load image\n",
    "            Y = np.array(RLE_decoder(row.values[0]))  # get segmentation mask from RLE\n",
    "            # apply augmentations\n",
    "            X = augment_image(image=X)['image'] / 255  # normalization after augmentation\n",
    "            res = augment_both(image=X, mask=Y)\n",
    "            yield res['image'], res['mask']\n",
    "        shuffled_df = df_train.sample(frac=1)  # reshuffle df\n",
    "        \n",
    "# generate pair of X and Y with shuffling\n",
    "def valid_generator():\n",
    "    shuffled_df = df_valid.sample(frac=1)  # create shuffled df\n",
    "    while True:\n",
    "        for index, row in shuffled_df.iterrows():\n",
    "            # load image and mask\n",
    "            X = np.array(tf.keras.utils.load_img(train_folder+index))  # load image\n",
    "            Y = np.array(RLE_decoder(row.values[0]))  # get segmentation mask from RLE\n",
    "            # apply augmentations\n",
    "            X = augment_image(image=X)['image'] / 255  # normalization after augmentation\n",
    "            res = augment_both(image=X, mask=Y)\n",
    "            yield res['image'], res['mask']\n",
    "        shuffled_df = df_valid.sample(frac=1)  # reshuffle df\n",
    "        \n",
    "# create Datasets from custom generators\n",
    "ds_train = tf.data.Dataset.from_generator(\n",
    "    train_generator, \n",
    "    output_shapes=((768,768,3), (768,768,1)),\n",
    "    output_types=(tf.float32, tf.float32))\n",
    "ds_valid = tf.data.Dataset.from_generator(\n",
    "    valid_generator, \n",
    "    output_shapes=((768,768,3), (768,768,1)),\n",
    "    output_types=(tf.float32, tf.float32))\n",
    "\n",
    "# optimize datasets\n",
    "ds_train = ds_train.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "ds_valid = ds_valid.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9590a888",
   "metadata": {},
   "source": [
    "## UNet set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "983d4064",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-02T18:20:31.520185Z",
     "iopub.status.busy": "2023-06-02T18:20:31.516482Z",
     "iopub.status.idle": "2023-06-02T18:20:31.540918Z",
     "shell.execute_reply": "2023-06-02T18:20:31.539381Z",
     "shell.execute_reply.started": "2023-06-02T18:20:31.520138Z"
    }
   },
   "outputs": [],
   "source": [
    "# define UNet architecture\n",
    "\n",
    "def down_block(inputs, features:int, factor:int):\n",
    "    conv = Conv2D(features, 3, activation='relu', padding='same')(inputs)\n",
    "    conv = BatchNormalization()(conv)\n",
    "    conv = Conv2D(features, 3, activation='relu', padding='same')(conv)\n",
    "    conv = BatchNormalization()(conv)\n",
    "    return MaxPooling2D(pool_size=factor)(conv), conv\n",
    "\n",
    "def up_block(inputs, skip_conn, features:int, factor:int):\n",
    "    up = Conv2DTranspose(features, factor, strides=factor, padding='same')(inputs)\n",
    "    up = BatchNormalization()(up)\n",
    "    up = concatenate([up, skip_conn])\n",
    "    conv = Conv2D(features, 3, activation='relu', padding='same')(up)\n",
    "    conv = BatchNormalization()(conv)\n",
    "    conv = Conv2D(features, 3, activation='relu', padding='same')(conv)\n",
    "    conv = BatchNormalization()(conv)\n",
    "    return conv\n",
    "\n",
    "def unet(input_size=(768, 768, 3)):\n",
    "    inputs = Input(input_size)\n",
    "    \n",
    "    # downsampling path\n",
    "    pool1, conv1 = down_block(inputs, 8, 2)\n",
    "    pool2, conv2 = down_block(pool1, 16, 2)\n",
    "    pool3, conv3 = down_block(pool2, 32, 2)\n",
    "    \n",
    "    # bottom of U-Net\n",
    "    conv_bottom = Conv2D(64, 3, activation='relu', padding='same')(pool3)\n",
    "    conv_bottom = Conv2D(64, 3, activation='relu', padding='same')(conv_bottom)\n",
    "    drop_bottom = Dropout(0.1)(conv_bottom)\n",
    "    \n",
    "    # upsampling path\n",
    "    conv4 = up_block(drop_bottom, conv3, 32, 2)\n",
    "    conv5 = up_block(conv4, conv2, 16, 2)\n",
    "    conv6 = up_block(conv5, conv1, 8, 2)\n",
    "\n",
    "    # output\n",
    "    outputs = Conv2D(1, 1, activation='sigmoid', padding='same')(conv6)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67d022ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-02T18:20:31.983276Z",
     "iopub.status.busy": "2023-06-02T18:20:31.982826Z",
     "iopub.status.idle": "2023-06-02T18:20:32.857676Z",
     "shell.execute_reply": "2023-06-02T18:20:32.856791Z",
     "shell.execute_reply.started": "2023-06-02T18:20:31.983240Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 768, 768, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 768, 768, 8)  224         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 768, 768, 8)  32         ['conv2d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 768, 768, 8)  584         ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 768, 768, 8)  32         ['conv2d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 384, 384, 8)  0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 384, 384, 16  1168        ['max_pooling2d[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 384, 384, 16  64         ['conv2d_2[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 384, 384, 16  2320        ['batch_normalization_2[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 384, 384, 16  64         ['conv2d_3[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 192, 192, 16  0          ['batch_normalization_3[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 192, 192, 32  4640        ['max_pooling2d_1[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 192, 192, 32  128        ['conv2d_4[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 192, 192, 32  9248        ['batch_normalization_4[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 192, 192, 32  128        ['conv2d_5[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 96, 96, 32)  0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 96, 96, 64)   18496       ['max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 96, 96, 64)   36928       ['conv2d_6[0][0]']               \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 96, 96, 64)   0           ['conv2d_7[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_transpose (Conv2DTransp  (None, 192, 192, 32  8224       ['dropout[0][0]']                \n",
      " ose)                           )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 192, 192, 32  128        ['conv2d_transpose[0][0]']       \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 192, 192, 64  0           ['batch_normalization_6[0][0]',  \n",
      "                                )                                 'batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 192, 192, 32  18464       ['concatenate[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 192, 192, 32  128        ['conv2d_8[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 192, 192, 32  9248        ['batch_normalization_7[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 192, 192, 32  128        ['conv2d_9[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_transpose_1 (Conv2DTran  (None, 384, 384, 16  2064       ['batch_normalization_8[0][0]']  \n",
      " spose)                         )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 384, 384, 16  64         ['conv2d_transpose_1[0][0]']     \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 384, 384, 32  0           ['batch_normalization_9[0][0]',  \n",
      "                                )                                 'batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 384, 384, 16  4624        ['concatenate_1[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 384, 384, 16  64         ['conv2d_10[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 384, 384, 16  2320        ['batch_normalization_10[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 384, 384, 16  64         ['conv2d_11[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_transpose_2 (Conv2DTran  (None, 768, 768, 8)  520        ['batch_normalization_11[0][0]'] \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 768, 768, 8)  32         ['conv2d_transpose_2[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 768, 768, 16  0           ['batch_normalization_12[0][0]', \n",
      "                                )                                 'batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 768, 768, 8)  1160        ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 768, 768, 8)  32         ['conv2d_12[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 768, 768, 8)  584         ['batch_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 768, 768, 8)  32         ['conv2d_13[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 768, 768, 1)  9           ['batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 121,945\n",
      "Trainable params: 121,385\n",
      "Non-trainable params: 560\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "model = unet()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713b6da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "model = tf.keras.models.load_model('model.h5', compile=False)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15b9b3e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-02T18:38:59.236290Z",
     "iopub.status.busy": "2023-06-02T18:38:59.235236Z",
     "iopub.status.idle": "2023-06-02T18:38:59.258140Z",
     "shell.execute_reply": "2023-06-02T18:38:59.256921Z",
     "shell.execute_reply.started": "2023-06-02T18:38:59.236221Z"
    }
   },
   "outputs": [],
   "source": [
    "# prepare model for training\n",
    "\n",
    "# dice score\n",
    "def dice_loss(y_true, y_pred, smooth=1e-7):\n",
    "    intersection = tf.reduce_sum(y_true * y_pred)\n",
    "    union = tf.reduce_sum(y_true) + tf.reduce_sum(y_pred)\n",
    "    dice = (2.0 * intersection + smooth) / (union + smooth)\n",
    "    return 1 - dice\n",
    "\n",
    "# learning rate decay\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=1e-2,\n",
    "    decay_steps=900,\n",
    "    decay_rate=0.7)\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule), loss=dice_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df29c5d4",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc053ca5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-02T18:39:20.607304Z",
     "iopub.status.busy": "2023-06-02T18:39:20.606304Z",
     "iopub.status.idle": "2023-06-02T18:39:20.614163Z",
     "shell.execute_reply": "2023-06-02T18:39:20.613094Z",
     "shell.execute_reply.started": "2023-06-02T18:39:20.607256Z"
    }
   },
   "outputs": [],
   "source": [
    "# set callbacks\n",
    "\n",
    "# saving best model\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath='model.h5',\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=True)\n",
    "\n",
    "# early stopping\n",
    "early_stop_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a2570d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-02T19:48:18.855371Z",
     "iopub.status.busy": "2023-06-02T19:48:18.854393Z",
     "iopub.status.idle": "2023-06-02T20:38:30.075588Z",
     "shell.execute_reply": "2023-06-02T20:38:30.070364Z",
     "shell.execute_reply.started": "2023-06-02T19:48:18.855336Z"
    }
   },
   "outputs": [],
   "source": [
    "# fit the model\n",
    "history = model.fit(ds_train, \n",
    "                    validation_data=ds_valid, \n",
    "                    steps_per_epoch=len(df_train) // batch_size, \n",
    "                    validation_steps=len(df_valid) // batch_size,\n",
    "                    epochs=100,\n",
    "                    callbacks=[checkpoint_callback, early_stop_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e672b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-02T18:05:39.859924Z",
     "iopub.status.busy": "2023-06-02T18:05:39.858882Z",
     "iopub.status.idle": "2023-06-02T18:05:40.128241Z",
     "shell.execute_reply": "2023-06-02T18:05:40.125550Z",
     "shell.execute_reply.started": "2023-06-02T18:05:39.859877Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label='train_loss')\n",
    "plt.plot(history.history['val_loss'], label='val_loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db3c841",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0099ddf0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
